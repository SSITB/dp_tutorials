{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZRyumBocHJF"
   },
   "source": [
    "# Тюториал 1.  Классификация текстов с использование векторных представлений слов\n",
    "\n",
    "Цель данного тюториала -- познакомить участников с применением **DeepPavlov** для классификации текстов.\n",
    "\n",
    "Тюториал имеет следующую структуру:\n",
    "\n",
    "1. [Установка зависимостей и библиотеки](#Установка-зависимостей-и-библиотеки)\n",
    "\n",
    "2. [Скачивание датасета](#Скачивание-датасета)\n",
    "\n",
    "3. [Dataset Reader](#Dataset-Reader): [docs link](https://deeppavlov.readthedocs.io/en/latest/apiref/dataset_readers.html)\n",
    "\n",
    "4. [Dataset Iterator](#Dataset-Iterator): [docs link](https://deeppavlov.readthedocs.io/en/latest/apiref/dataset_iterators.html)\n",
    "\n",
    "5. [Preprocessor](#Preprocessor): [docs link](https://deeppavlov.readthedocs.io/en/latest/components/data_processors.html)\n",
    "\n",
    "6. [Tokenizer](#Tokenizer): [docs link](https://deeppavlov.readthedocs.io/en/latest/components/data_processors.html)\n",
    "\n",
    "7. [GloVe Embedder](#Embedder): [docs link](https://deeppavlov.readthedocs.io/en/latest/components/data_processors.html)\n",
    "[pre-trained embeddings link](https://deeppavlov.readthedocs.io/en/latest/intro/pretrained_vectors.html)\n",
    "\n",
    "8. [Vocabulary of classes](#Vocabulary-of-classes)\n",
    "\n",
    "9. [Keras Classifier](#Classifier): [docs link](https://deeppavlov.readthedocs.io/en/latest/components/classifiers.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wFSAIVwcHJt"
   },
   "source": [
    "## Установка зависимостей и библиотеки\n",
    "\n",
    "Начнем с установки библиотеки `DeepPavlov` и дополнительных зависимостей для использвоания нейросетевой модели классификации на `Keras` с `TensorFlow` бэкендом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "82JKwt5_cHJu",
    "outputId": "68e1a748-76c0-4b30-af8c-041410868289"
   },
   "outputs": [],
   "source": [
    "!pip install deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 978
    },
    "colab_type": "code",
    "id": "8foXOlPocHJv",
    "outputId": "1f7d58ca-10b9-4d6b-e2f3-84b02832e79e"
   },
   "outputs": [],
   "source": [
    "!python -m deeppavlov install intents_snips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rBjOVuFVE1P4"
   },
   "source": [
    "## Скачивание датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pRMjDk79E1Xf"
   },
   "source": [
    "Данный тюториал использует датасет Stanford Sentiment Treebank (SST), описанный в [статье](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf).\n",
    "\n",
    "Датасет содержит набор неразмеченных предложений, разделенных на тренировочную, валидационную и тестовую выборку, а также набор фраз, каждой из которых сопоставлено значение тональности от 0 до 1.\n",
    "Большинство предложений содержатся в наборе фраз. \n",
    "Соответственно, мы выбрали только те предложения, что размечены по тональности, для каждой выборки. \n",
    "Также мы преобразовали значение тональности, разделив интервал от 0 до 1.\n",
    "Для решения многоклассовой задачи классификации разделим интервал на 5 частей: 0.0-0.2 - очень негативные, 0.2-0.4 - негативные, 0.4-0.6 - нейтральные, 0.6-0.8 - позитивные, 0.8-1.0 - очень позитивные.\n",
    "Для сведения к двум классам разделим интервал следующим образом: 0.0-0.4 - негативные, 0.6-1.0 - позитивные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X2CSOOvQE6wA"
   },
   "source": [
    "Скачаем архив с датасетом и извлечем его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "9evo51p-E6_u",
    "outputId": "707d48e3-ac91-4fb4-8c34-2665edf35327"
   },
   "outputs": [],
   "source": [
    "from deeppavlov.core.data.utils import download\n",
    "\n",
    "download(\"./stanfordSentimentTreebank.zip\", source_url=\"http://files.deeppavlov.ai/datasets/stanfordSentimentTreebank.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "colab_type": "code",
    "id": "eGe8JOi6FBBS",
    "outputId": "16c28985-9ffc-43f9-d330-ea63d237f12d"
   },
   "outputs": [],
   "source": [
    "!unzip stanfordSentimentTreebank.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "JhY2yQcoFEb0",
    "outputId": "1ed704fb-0028-4594-eaec-18dcd20b246d"
   },
   "outputs": [],
   "source": [
    "!ls stanfordSentimentTreebank/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-3ecyN0XcHJw"
   },
   "source": [
    "## Dataset Reader\n",
    "\n",
    "DatasetReader - компонента библиотеки для чтения файлов. `DeepPavlov` содержит несколько различных DatasetReaders, пользователи могут как использовать уже готовый DatasetReader, так и написать свою компоненту для чтения данных, однако стоит учитывать, что данные на выходе должны быть в определенном формате. \n",
    "\n",
    "Требования к **DatasetReader**: \n",
    "* на выходе метода `read` должен быть словарь с тремя ключами \"train\", \"valid\" и \"test\", \n",
    "* каждый элемент словаря - лист соответствующих примеров,\n",
    "* каждый пример - tuple `(x, y)`, где `x` и `y` также могут быть листами соответствующих входных данных (например, `x` может быть листом из двух входных текстов, а `y` - листом классов, к которому принадлежит пример).\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/dataset_readers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sSgPZbPAcHJx"
   },
   "outputs": [],
   "source": [
    "from deeppavlov.dataset_readers.basic_classification_reader import BasicClassificationDatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7IMfseBmcHJy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reader = BasicClassificationDatasetReader()\n",
    "data = reader.read(data_path=\"./stanfordSentimentTreebank\", \n",
    "                   train=\"train_binary.csv\", valid=\"valid_binary.csv\", test=\"test_binary.csv\",\n",
    "                   x=\"text\", y=\"binary_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yHMgaOdfcHJz",
    "outputId": "91829aee-0ed7-4754-ec47-7bc5539a7460"
   },
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Si7P1UU6cHJ1"
   },
   "source": [
    "Для задачи классификации по умолчанию каждому примеру ставится в соответствие лист классов. Это сделано для единообразия работы как с многоклассовой классификацией, так и с многолейбловой (когда каждому примеру может соответствовать один или несколько классов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "iMTGWqyJcHJ2",
    "outputId": "d792024d-078b-4b13-dfa8-1079adaeac18"
   },
   "outputs": [],
   "source": [
    "data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4o1sPsrcHJ3"
   },
   "source": [
    "## Dataset Iterator\n",
    "\n",
    "DatasetIterator - компонента библиотеки для итерирования по датасету (создания батчей, получения всех примеров). `DeepPavlov` содержит несколько разных DatasetIterators, пользователи могут как использовать уже готовый DatasetIterator, так и написать свою компоненту для итерирования по данным\n",
    "\n",
    "DatasetIterator должен иметь следующие методы:\n",
    "\n",
    "* **gen_batches** - метод для генерации батчей входных пар для обучения или инференса нейронной сети. На выходе метода - tuple `(x, y)` из двух листов входных данных `x` и `y`. \n",
    "* **get_instances** - метод для получения данных определенного набора (\"train\", \"valid\", \"test\"). На выходе - tuple `(x, y)` всех элементов входных данных этого набора.\n",
    "* **split** - метод для разделения наборов данных на несколько (\"train\", \"valid\", \"test\").\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/dataset_iterators.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1iWNhFmcHJ4"
   },
   "outputs": [],
   "source": [
    "from deeppavlov.dataset_iterators.basic_classification_iterator import BasicClassificationDatasetIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LtY4xKMcHJ5"
   },
   "outputs": [],
   "source": [
    "iterator = BasicClassificationDatasetIterator(data, seed=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "enx-deI6Fc81",
    "outputId": "89fb5012-9915-4706-db15-dbb78cf27722"
   },
   "outputs": [],
   "source": [
    "for batch in iterator.gen_batches(data_type=\"train\", batch_size=13):\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7q-San0cHJ6"
   },
   "source": [
    "## Preprocessor\n",
    "\n",
    "Предобработать текст можно, используя различные компоненты либо написав свою.\n",
    "В данном тюториале воспользуемся самым простым - lower-casing.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/preprocessors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "wHzWodEgcHJ7",
    "outputId": "ef91fe58-6b27-493d-a60d-18089511ea10"
   },
   "outputs": [],
   "source": [
    "from deeppavlov.models.preprocessors.str_lower import StrLower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iP0hUsI5cHJ9"
   },
   "outputs": [],
   "source": [
    "preprocessor = StrLower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bQt4cfRzcHJ_",
    "outputId": "f38233f4-9e6f-465d-d7d7-a24017dcfe5c"
   },
   "outputs": [],
   "source": [
    "preprocessor([\"The Rock is destined to be the 21st Century 's new `` Conan ''.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t3vA74rscHKC"
   },
   "source": [
    "## Tokenizer\n",
    "\n",
    "Для использования потокенных (пословных) векторных представлений необходимо разделить предобработанный текст на токены (слов и пунктуационные символы).\n",
    "`DeepPavlov` содержит несколько различных токенизаторов. Пользователи могут выбрать любой.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/tokenizers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcrmkaFZcHKD"
   },
   "outputs": [],
   "source": [
    "from deeppavlov.models.tokenizers.nltk_tokenizer import NLTKTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b_HxUZoacHKE"
   },
   "outputs": [],
   "source": [
    "tokenizer = NLTKTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "DQmVPhS2cHKF",
    "outputId": "a308ce69-b20a-4894-bce9-b43be5049cdc"
   },
   "outputs": [],
   "source": [
    "tokenizer([\"The Rock is destined to be the 21st Century 's new `` Conan ''.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZqCHoa0YcHKH"
   },
   "source": [
    "## Embedder\n",
    "\n",
    "В данном тюториале используем недообучаемые векторные представления GloVe. \n",
    "Все компоненты для получения векторных представлений текстов унифицированы, поэтому пользователи могут использовать любые векторные представления из предложенных в документации: GloVe, fastText, ELMo.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/embedders.html\n",
    "\n",
    "Скачаем файл с векторными представлениями GloVe. Данный файл был скачан [отсюда](https://nlp.stanford.edu/projects/glove/), но по ссылке скачивается еще несколько других файлов (в итоге более 800 Mb). Для того, чтобы сберечь наше время, скачаем файл с векторными представлениями с `DeepPavlov` (скачивает 350 Mb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "8BDAP9GVcHKI",
    "outputId": "7d02a4f0-a103-41d1-8e74-d4261b1c82d3"
   },
   "outputs": [],
   "source": [
    "from deeppavlov.core.data.utils import download\n",
    "\n",
    "download(\"./glove.6B.100d.txt\", source_url=\"http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g9UH7BfxcHKJ"
   },
   "source": [
    "Now we can define GloVeEmbedder. Parameter `pad_zero` which is set to `True` determines whether to pad embedded batch of tokens to the longest sample length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "SP0yUvrXcHKK",
    "outputId": "663ec73e-59a0-4085-f42a-71088901a9e3"
   },
   "outputs": [],
   "source": [
    "from deeppavlov.models.embedders.glove_embedder import GloVeEmbedder\n",
    "\n",
    "embedder = GloVeEmbedder(load_path=\"./glove.6B.100d.txt\", \n",
    "                         pad_zero=True  # means whether to pad up to the longest sample in a batch\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "539oiSQ4YHZV",
    "outputId": "a53288fd-f8ee-4773-eb85-29fe58abee9b"
   },
   "outputs": [],
   "source": [
    "embedder.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "km2NCO5McHKL",
    "outputId": "c1b48ff2-8255-4e14-c057-810c7443d4ca"
   },
   "outputs": [],
   "source": [
    "embedder(tokenizer(preprocessor([\"The Rock is destined to be the 21st Century 's new 'Conan'.\",\n",
    "                                 \"The Rock is a new 'Conan'.\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pqqIo_6FcHKN",
    "outputId": "f98042b8-3e52-4e64-8f84-5abf4ac59f20"
   },
   "outputs": [],
   "source": [
    "embedder(tokenizer(preprocessor([\"The Rock is destined to be the 21st Century 's new 'Conan'.\",\n",
    "                                 \"The Rock is a new 'Conan'.\"]))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdyZP9obcHKO"
   },
   "source": [
    "## Vocabulary of classes\n",
    "\n",
    "По умолчанию каждый класс считывается и хранится в виде строки.\n",
    "Поэтому мы должны просмотреть все встречающиеся в датасете классы, собрать по ним словарь, а затем преобразовать классы в индексы.\n",
    "\n",
    "Нейросетевые классификаторы принимают one-hot представление распределения по классам, а возвращают распределение вероятностей принадлежности классам.\n",
    "Чтобы получить one-hot представление классов, необходимо также преобразовать полученные из словаря индексы классов.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/core/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wZMh_6VcHKO"
   },
   "outputs": [],
   "source": [
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "_7O0c273cHKQ",
    "outputId": "d40948d1-c244-4944-f256-cabb8fbd309f"
   },
   "outputs": [],
   "source": [
    "vocab = SimpleVocabulary(save_path=\"./binary_classes.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OpRDirSeXLav",
    "outputId": "e97e2e19-fc1a-4770-babd-d6d5d95fc1ee"
   },
   "outputs": [],
   "source": [
    "iterator.get_instances(data_type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KO_XRoi0cHKS"
   },
   "outputs": [],
   "source": [
    "vocab.fit(iterator.get_instances(data_type=\"train\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WqrLgM3wcHKU",
    "outputId": "9885bc33-7f88-4053-b11e-e2ad9374c7d7"
   },
   "outputs": [],
   "source": [
    "list(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "07UYYS-bcHKW",
    "outputId": "612b524c-a5a6-4b9e-b149-0ddd380dfff4"
   },
   "outputs": [],
   "source": [
    "vocab([\"positive\", \"positive\", \"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UJgn639-cHKZ",
    "outputId": "8ead8862-3256-4634-c699-6ee131a930d2"
   },
   "outputs": [],
   "source": [
    "vocab([0, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFpd2ciccHKc"
   },
   "source": [
    "**One-hotter**\n",
    "\n",
    "Компонента для преобразования индексов в one-hot представление.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/preprocessors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiXLIj4EcHKc"
   },
   "outputs": [],
   "source": [
    "from deeppavlov.models.preprocessors.one_hotter import OneHotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EtTb1VgcHKe"
   },
   "outputs": [],
   "source": [
    "one_hotter = OneHotter(depth=vocab.len, \n",
    "                       single_vector=True  # means we want to have one vector per sample\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "YTh-O4uvcHKg",
    "outputId": "f8eed7c6-be1b-4cd8-fcce-e87f18e15c16"
   },
   "outputs": [],
   "source": [
    "one_hotter(vocab([\"positive\", \"positive\", \"negative\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgjLcf5McHKh"
   },
   "source": [
    "**Converting from probability to labels**\n",
    "\n",
    "Так как нейросетевые модели возвращают вероятности распределения по классам, поэтому нам необходимо также преобразовать вектора вероятностей в классы.\n",
    "Для этого используем `Proba2Labels` компоненту для преобразования вероятнсотей в индексы, а далее словарь по классам для преобразования индексов в текстовые назвнаия классов.\n",
    "\n",
    "`Proba2Labels` компонента имеет несколько режимов:\n",
    "* если `max_proba`=true, возвращает индексы с наибольшей вероятностью,\n",
    "* если задано значение `confident_threshold` (от 0 до 1), возвращает индексы, вероятность принадлежности к классам которых выше заданного порога,\n",
    "* если задано целочисленное значение `top_n`, возвращает `top_n` индексов с наибольшими вероятностями.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/preprocessors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwZ_zKZYcHKi"
   },
   "outputs": [],
   "source": [
    "from deeppavlov.models.classifiers.proba2labels import Proba2Labels\n",
    "\n",
    "prob2labels = Proba2Labels(max_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n4eKuCvqYkqZ",
    "outputId": "a84377d0-1bef-4464-f1f3-b8a363317764"
   },
   "outputs": [],
   "source": [
    "vocab.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zVsUXstmcHKk",
    "outputId": "ecfe12fe-d483-49b1-a0ff-2fe5551644dc"
   },
   "outputs": [],
   "source": [
    "prob2labels([[0.6, 0.4], \n",
    "             [0.2, 0.8],\n",
    "             [0.1, 0.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1qCNgjSVGOMP",
    "outputId": "e5c66e10-0939-4359-f9bc-b0620d7b284d"
   },
   "outputs": [],
   "source": [
    "vocab(prob2labels([[0.6, 0.4], \n",
    "                   [0.2, 0.8],\n",
    "                   [0.1, 0.9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnUUkw_AcHKo"
   },
   "source": [
    "## Classifier\n",
    "\n",
    "`DeepPavlov` содержит несколько различных моделей для классификации текстов: классификаторы `sklearn`, нейросетевые модели на `Keras` с `TensorFlow` бэкендом, классификатор на основе BERT  архитектуры на `TensorFlow`.\n",
    "Данный тюториал демонстрирует, как построить нейросетевой классификатор неглубокой широкой свёрточной сети (shallow and wide Convolutional Neural Network) на `Keras`. \n",
    "\n",
    "`KerasClassificationModel` - класс-компонента, строящий `Keras` классификатор, а архитектура сети задается в отдельном методе класса.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/classifiers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XgGTTfgqcHKo",
    "outputId": "97bc4ef2-30dc-4a56-a47a-e73c1137f042"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Activation, Dropout, Flatten, GlobalMaxPooling1D\n",
    "from keras import Model\n",
    "\n",
    "from deeppavlov.models.classifiers.keras_classification_model import KerasClassificationModel\n",
    "from deeppavlov.metrics.accuracy import sets_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tM6IoNGqcHKp",
    "outputId": "e5520967-3419-41c5-b985-988937efa8e4"
   },
   "outputs": [],
   "source": [
    "model = KerasClassificationModel(\n",
    "    filters_cnn=256,\n",
    "    kernel_sizes_cnn=[3,5,7],\n",
    "    dropout_rate=0.2,\n",
    "    dense_size=100,\n",
    "    save_path=\"./cnn_model_v0\", \n",
    "    load_path=\"./cnn_model_v0\", \n",
    "    embedding_size=embedder.dim,\n",
    "    n_classes=vocab.len,\n",
    "    model_name=\"cnn_model\",  # HERE we put our new network-method name\n",
    "    optimizer=\"Adam\",\n",
    "    learning_rate=0.001,\n",
    "    learning_rate_decay=0.001,\n",
    "    loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "7ITs_wpucHKq",
    "outputId": "251d5b68-fe35-4052-ee69-a3961e011118",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Method `get_instances` returns all the samples of particular data field\n",
    "x_valid, y_valid = iterator.get_instances(data_type=\"valid\")\n",
    "# You need to save model only when validation score is higher than previous one.\n",
    "# This variable will contain the highest accuracy score\n",
    "best_score = 0.\n",
    "patience = 2\n",
    "impatience = 0\n",
    "\n",
    "# let's train for 10 epochs\n",
    "for ep in range(10):\n",
    "    \n",
    "    for x, y in iterator.gen_batches(batch_size=64, \n",
    "                                     data_type=\"train\", shuffle=True):\n",
    "        x_embed = embedder(tokenizer(preprocessor(x)))\n",
    "        y_onehot = one_hotter(vocab(y))\n",
    "        model.train_on_batch(x_embed, y_onehot)\n",
    "        \n",
    "    y_valid_pred = model(embedder(tokenizer(preprocessor(x_valid))))\n",
    "    score = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))\n",
    "    print(\"Epochs done: {}. Valid Accuracy: {}\".format(ep + 1, score))\n",
    "    if score > best_score:\n",
    "        model.save()\n",
    "        print(\"New best score. Saving model.\")\n",
    "        best_score = score    \n",
    "        impatience = 0\n",
    "    else:\n",
    "        impatience += 1\n",
    "        if impatience == patience:\n",
    "            print(\"Out of patience. Stop training.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "6mXMUtrpcHKt",
    "outputId": "582733fe-888b-4095-fe61-aaafbe9be575"
   },
   "outputs": [],
   "source": [
    "# Let's look into obtained resulting outputs\n",
    "print(\"Text sample: {}\".format(x_valid[0]))\n",
    "print(\"True label: {}\".format(y_valid[0]))\n",
    "print(\"Predicted probability distribution: {}\".format(dict(zip(vocab.keys(), \n",
    "                                                               y_valid_pred[0]))))\n",
    "print(\"Predicted label: {}\".format(vocab(prob2labels(y_valid_pred))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u55H8o1VcHKv"
   },
   "source": [
    "# Подключение к Telegram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UESbbxL7cHKz"
   },
   "source": [
    "`DeepPavlov` поддерживает подключение моделей и ботов к следующим сервисам:\n",
    "\n",
    "* [REST API](http://docs.deeppavlov.ai/en/master/intro/features.html#examples-of-some-components)\n",
    "* [Telegram](http://docs.deeppavlov.ai/en/master/intro/features.html#examples-of-some-components)\n",
    "* [Amazon Alexa](http://docs.deeppavlov.ai/en/master/devguides/amazon_alexa.html)\n",
    "* [Microsoft Bot Framework](http://docs.deeppavlov.ai/en/master/devguides/ms_bot_integration.html)\n",
    "  * Bing, Cortana, Email, Facebook Messenger, Slack, GroupMe, Microsoft Teams, Skype, Telegram, Twilio, Web Chat\n",
    "* [Yandex Alice](http://docs.deeppavlov.ai/en/master/devguides/yandex_alice.html)\n",
    "\n",
    "В данном тюториале рассмотрим, как подключить полученную модель к Telegram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключение из командной строки\n",
    "\n",
    "`DeepPavlov` использует следующие команды:\n",
    "\n",
    "Запустить модель в интерфейсе командной строки:\n",
    "```\n",
    "python -m deeppavlov interact model_config\n",
    "```\n",
    "\n",
    "Поднять REST API:\n",
    "```\n",
    "python -m deeppavlov riseapi model_config\n",
    "```\n",
    "\n",
    "Подключить к Telegram:\n",
    "```\n",
    "python -m deeppavlov interactbot model_config -t <TELEGRAM_TOKEN>\n",
    "```\n",
    "\n",
    "Telegram token может быть создан с помощью  @BotFather. Подробнее прочитайте [здесь](https://core.telegram.org/bots#3-how-do-i-create-a-bot)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключение без конфига\n",
    "\n",
    "В данном тюториале мы не создавали конфиг для модели, поэтому давайте попробуем поднять сервис, также не используя конфиг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentPipeline:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, input_texts):\n",
    "        '''\n",
    "        __call__ method should return responses for each utterance in input_texts\n",
    "        '''\n",
    "        \n",
    "        sentiment_labels = vocab(prob2labels(model(embedder(tokenizer(preprocessor(input_texts))))))\n",
    "        sentiment_labels = [lab[0] for lab in sentiment_labels]\n",
    "        \n",
    "        return sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_config(class_name):\n",
    "    \"\"\"generate minimal required DeepPavlov model configuration\"\"\"\n",
    "\n",
    "    config = {\n",
    "        'chainer': {\n",
    "            'in': ['x'],\n",
    "            'out': ['y'],\n",
    "            'pipe': [\n",
    "                {\n",
    "                    'class_name': f'__main__:{class_name}',\n",
    "                    'in': ['x'],\n",
    "                    'out': ['y']\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to interact with CLI\n",
    "from deeppavlov.core.commands.infer import interact_model\n",
    "# to interact with Telegram\n",
    "from deeppavlov.utils.telegram.telegram_ui import interact_model_by_telegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_model(generate_config('SentimentPipeline'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_model_by_telegram(generate_config('SentimentPipeline'), \n",
    "                           token='YOUR_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tutorial_1_Sentence_classification_with_word_embeddings.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Deep36_reserve",
   "language": "python",
   "name": "deep36_reserve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
