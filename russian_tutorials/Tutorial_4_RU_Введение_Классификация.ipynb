{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZRyumBocHJF"
   },
   "source": [
    "# Тюториал 4. Введение.  Классификация текстов \n",
    "\n",
    "Цель данного тюториала -- познакомить участников с базовым вариантом использованием **DeepPavlov**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Документация\n",
    "\n",
    "Документация по моделям и коду: http://docs.deeppavlov.ai\n",
    "\n",
    "Для бизнеса: http://ipavlov.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wFSAIVwcHJt"
   },
   "source": [
    "## Установка зависимостей и библиотеки\n",
    "\n",
    "Начнем с установки библиотеки `DeepPavlov`:\n",
    "```\n",
    "pip install deeppavlov\n",
    "```\n",
    "а также дополнительных зависимостей для использования нейросетевой модели классификации на `Keras` с `TensorFlow` бэкендом.\n",
    "```\n",
    "python -m deeppavlov install <config_path>\n",
    "```\n",
    "где `<config_path>` - путь к файлу-конфигу выбранной модели (например, `deeppavlov/configs/classifiers/intents_snips.json`) или просто название файла без расширения (например, `intents_snips`).\n",
    "\n",
    "## Скачивание\n",
    "\n",
    "Чтобы использовать модель для получения предсказаний в командной строке, запустите:\n",
    "```\n",
    "python -m deeppavlov interact <config_path> [-d]\n",
    "```\n",
    "где флаг ``-d`` скачивает необходимые данные -- файлы предобученной модели, эмбеддинги, файлы датасета (optional).\n",
    "\n",
    "Натренировать модель можно следующим образом:\n",
    "```\n",
    "python -m deeppavlov train <config_path> [-d]\n",
    "```\n",
    "Общий список возможных режимов запуска следующий:\n",
    "```\n",
    "python -m deeppavlov <action> <config_path> [-d]\n",
    "```\n",
    "* ``<action>`` может принимать следующие занчения:\n",
    "    * ``download`` -- скачать данные модели (то же самое, что указать для любой другой команды флаг ``-d``),\n",
    "    * ``train`` -- натренировать модель на данных, указанных в конфиге,\n",
    "    * ``evaluate`` -- посчитать значения метрик на исходном датасете,\n",
    "    * ``interact`` -- вызов пайплайна на предикт в командной строке,\n",
    "    * ``riseapi`` -- поднять REST API сервер (см. [docs](http://docs.deeppavlov.ai/en/master/integrations/rest_api.html)),\n",
    "    * ``interactbot`` -- поднять пайплайн как Telegram bot (см. [docs](http://docs.deeppavlov.ai/en/master/integrations/telegram.html)),\n",
    "    * ``interactmsbot`` -- поднять пайплайн как Miscrosoft Bot Framework сервер (см. [docs](http://docs.deeppavlov.ai/en/master/integrations/ms_bot.html)),\n",
    "    * ``predict`` -- получить предикты для прмиеров из `stdin` или из `<file_path>`, если ``-f <file_path>`` указан.\n",
    "* ``<config_path>`` -- полный путь или название файла-конфига.\n",
    "* ``-d`` скачивает необходимые данные.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конфигурационный файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pathlib.PosixPath'> /home/dilyara/Documents/GitHub/DeepPavlov/deeppavlov/configs/classifiers/rusentiment_elmo_twitter_cnn.json\n",
      "{\n",
      "  \"dataset_reader\": {\n",
      "    \"class_name\": \"basic_classification_reader\",\n",
      "    \"x\": \"text\",\n",
      "    \"y\": \"label\",\n",
      "    \"data_path\": \"{DOWNLOADS_PATH}/rusentiment/\",\n",
      "    \"train\": \"rusentiment_random_posts.csv\",\n",
      "    \"test\": \"rusentiment_test.csv\"\n",
      "  },\n",
      "  \"dataset_iterator\": {\n",
      "    \"class_name\": \"basic_classification_iterator\",\n",
      "    \"seed\": 42,\n",
      "    \"field_to_split\": \"train\",\n",
      "    \"split_seed\": 23,\n",
      "    \"split_fields\": [\n",
      "      \"train\",\n",
      "      \"valid\"\n",
      "    ],\n",
      "    \"split_proportions\": [\n",
      "      0.9,\n",
      "      0.1\n",
      "    ]\n",
      "  },\n",
      "  \"chainer\": {\n",
      "    \"in\": [\n",
      "      \"x\"\n",
      "    ],\n",
      "    \"in_y\": [\n",
      "      \"y\"\n",
      "    ],\n",
      "    \"pipe\": [\n",
      "      {\n",
      "        \"id\": \"classes_vocab\",\n",
      "        \"class_name\": \"simple_vocab\",\n",
      "        \"fit_on\": [\n",
      "          \"y\"\n",
      "        ],\n",
      "        \"save_path\": \"{MODEL_PATH}/classes.dict\",\n",
      "        \"load_path\": \"{MODEL_PATH}/classes.dict\",\n",
      "        \"in\": \"y\",\n",
      "        \"out\": \"y_ids\"\n",
      "      },\n",
      "      {\n",
      "        \"in\": [\n",
      "          \"x\"\n",
      "        ],\n",
      "        \"out\": [\n",
      "          \"x_prep\"\n",
      "        ],\n",
      "        \"class_name\": \"dirty_comments_preprocessor\",\n",
      "        \"remove_punctuation\": false\n",
      "      },\n",
      "      {\n",
      "        \"in\": \"x_prep\",\n",
      "        \"out\": \"x_tok\",\n",
      "        \"id\": \"my_tokenizer\",\n",
      "        \"class_name\": \"nltk_tokenizer\",\n",
      "        \"tokenizer\": \"wordpunct_tokenize\"\n",
      "      },\n",
      "      {\n",
      "        \"in\": [\n",
      "          \"x_tok\"\n",
      "        ],\n",
      "        \"out\": [\n",
      "          \"x_emb\"\n",
      "        ],\n",
      "        \"id\": \"my_embedder\",\n",
      "        \"class_name\": \"elmo_embedder\",\n",
      "        \"elmo_output_names\": [\n",
      "          \"elmo\"\n",
      "        ],\n",
      "        \"mini_batch_size\": 32,\n",
      "        \"spec\": \"http://files.deeppavlov.ai/deeppavlov_data/elmo_ru-twitter_2013-01_2018-04_600k_steps.tar.gz\",\n",
      "        \"pad_zero\": true\n",
      "      },\n",
      "      {\n",
      "        \"in\": \"y_ids\",\n",
      "        \"out\": \"y_onehot\",\n",
      "        \"class_name\": \"one_hotter\",\n",
      "        \"depth\": \"#classes_vocab.len\",\n",
      "        \"single_vector\": true\n",
      "      },\n",
      "      {\n",
      "        \"in\": [\n",
      "          \"x_emb\"\n",
      "        ],\n",
      "        \"in_y\": [\n",
      "          \"y_onehot\"\n",
      "        ],\n",
      "        \"out\": [\n",
      "          \"y_pred_probas\"\n",
      "        ],\n",
      "        \"main\": true,\n",
      "        \"class_name\": \"keras_classification_model\",\n",
      "        \"save_path\": \"{MODEL_PATH}/model\",\n",
      "        \"load_path\": \"{MODEL_PATH}/model\",\n",
      "        \"embedding_size\": \"#my_embedder.dim\",\n",
      "        \"n_classes\": \"#classes_vocab.len\",\n",
      "        \"kernel_sizes_cnn\": [\n",
      "          3,\n",
      "          5,\n",
      "          7\n",
      "        ],\n",
      "        \"filters_cnn\": 256,\n",
      "        \"optimizer\": \"Adam\",\n",
      "        \"learning_rate\": 0.01,\n",
      "        \"learning_rate_decay\": 0.1,\n",
      "        \"loss\": \"categorical_crossentropy\",\n",
      "        \"last_layer_activation\": \"softmax\",\n",
      "        \"coef_reg_cnn\": 0.001,\n",
      "        \"coef_reg_den\": 0.01,\n",
      "        \"dropout_rate\": 0.5,\n",
      "        \"dense_size\": 100,\n",
      "        \"model_name\": \"cnn_model\"\n",
      "      },\n",
      "      {\n",
      "        \"in\": \"y_pred_probas\",\n",
      "        \"out\": \"y_pred_ids\",\n",
      "        \"class_name\": \"proba2labels\",\n",
      "        \"max_proba\": true\n",
      "      },\n",
      "      {\n",
      "        \"in\": \"y_pred_ids\",\n",
      "        \"out\": \"y_pred_labels\",\n",
      "        \"ref\": \"classes_vocab\"\n",
      "      }\n",
      "    ],\n",
      "    \"out\": [\n",
      "      \"y_pred_labels\"\n",
      "    ]\n",
      "  },\n",
      "  \"train\": {\n",
      "    \"epochs\": 100,\n",
      "    \"batch_size\": 128,\n",
      "    \"metrics\": [\n",
      "      \"f1_weighted\",\n",
      "      \"f1_macro\",\n",
      "      \"sets_accuracy\",\n",
      "      {\n",
      "        \"name\": \"roc_auc\",\n",
      "        \"inputs\": [\n",
      "          \"y_onehot\",\n",
      "          \"y_pred_probas\"\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"validation_patience\": 5,\n",
      "    \"val_every_n_epochs\": 1,\n",
      "    \"log_every_n_epochs\": 1,\n",
      "    \"show_examples\": false,\n",
      "    \"evaluation_targets\": [\n",
      "      \"train\",\n",
      "      \"valid\",\n",
      "      \"test\"\n",
      "    ],\n",
      "    \"tensorboard_log_dir\": \"{MODEL_PATH}/logs\",\n",
      "    \"class_name\": \"nn_trainer\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"variables\": {\n",
      "      \"ROOT_PATH\": \"~/.deeppavlov\",\n",
      "      \"DOWNLOADS_PATH\": \"{ROOT_PATH}/downloads\",\n",
      "      \"MODELS_PATH\": \"{ROOT_PATH}/models\",\n",
      "      \"MODEL_PATH\": \"{MODELS_PATH}/classifiers/rusentiment_v10\"\n",
      "    },\n",
      "    \"requirements\": [\n",
      "      \"{DEEPPAVLOV_PATH}/requirements/tf.txt\",\n",
      "      \"{DEEPPAVLOV_PATH}/requirements/tf-hub.txt\"\n",
      "    ],\n",
      "    \"labels\": {\n",
      "      \"telegram_utils\": \"IntentModel\",\n",
      "      \"server_utils\": \"KerasIntentModel\"\n",
      "    },\n",
      "    \"download\": [\n",
      "      {\n",
      "        \"url\": \"http://files.deeppavlov.ai/deeppavlov_data/classifiers/rusentiment_v10.tar.gz\",\n",
      "        \"subdir\": \"{MODELS_PATH}/classifiers\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from deeppavlov import configs\n",
    "\n",
    "config_path = configs.classifiers.rusentiment_elmo_twitter_cnn\n",
    "print(type(config_path), config_path)\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Reader\n",
    "\n",
    "DatasetReader - компонента библиотеки для чтения файлов. `DeepPavlov` содержит несколько различных DatasetReaders, пользователи могут как использовать уже готовый DatasetReader, так и написать свою компоненту для чтения данных, однако стоит учитывать, что данные на выходе должны быть в определенном формате. \n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/dataset_readers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"class_name\": \"basic_classification_reader\",\n",
      "  \"x\": \"text\",\n",
      "  \"y\": \"label\",\n",
      "  \"data_path\": \"{DOWNLOADS_PATH}/rusentiment/\",\n",
      "  \"train\": \"rusentiment_random_posts.csv\",\n",
      "  \"test\": \"rusentiment_test.csv\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(config[\"dataset_reader\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4o1sPsrcHJ3"
   },
   "source": [
    "## Dataset Iterator\n",
    "\n",
    "DatasetIterator - компонента библиотеки для итерирования по датасету (создания батчей, получения всех примеров). `DeepPavlov` содержит несколько разных DatasetIterators, пользователи могут как использовать уже готовый DatasetIterator, так и написать свою компоненту для итерирования по данным.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/dataset_iterators.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"class_name\": \"basic_classification_iterator\",\n",
      "  \"seed\": 42,\n",
      "  \"field_to_split\": \"train\",\n",
      "  \"split_seed\": 23,\n",
      "  \"split_fields\": [\n",
      "    \"train\",\n",
      "    \"valid\"\n",
      "  ],\n",
      "  \"split_proportions\": [\n",
      "    0.9,\n",
      "    0.1\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(config[\"dataset_iterator\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7q-San0cHJ6"
   },
   "source": [
    "## Preprocessor\n",
    "\n",
    "Предобработать текст можно, используя различные компоненты либо написав свою.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/preprocessors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "wHzWodEgcHJ7",
    "outputId": "ef91fe58-6b27-493d-a60d-18089511ea10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"in\": [\n",
      "    \"x\"\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"x_prep\"\n",
      "  ],\n",
      "  \"class_name\": \"dirty_comments_preprocessor\",\n",
      "  \"remove_punctuation\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(config[\"chainer\"][\"pipe\"][1], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t3vA74rscHKC"
   },
   "source": [
    "## Tokenizer\n",
    "\n",
    "Для использования потокенных (пословных) векторных представлений необходимо разделить предобработанный текст на токены (слов и пунктуационные символы).\n",
    "`DeepPavlov` содержит несколько различных токенизаторов. \n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/tokenizers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcrmkaFZcHKD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"in\": \"x_prep\",\n",
      "  \"out\": \"x_tok\",\n",
      "  \"id\": \"my_tokenizer\",\n",
      "  \"class_name\": \"nltk_tokenizer\",\n",
      "  \"tokenizer\": \"wordpunct_tokenize\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(config[\"chainer\"][\"pipe\"][2], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZqCHoa0YcHKH"
   },
   "source": [
    "## Embedder\n",
    "\n",
    "В данном тюториале используем недообучаемые векторные представления ELMo. \n",
    "Все компоненты для получения векторных представлений текстов унифицированы, поэтому пользователи могут использовать любые векторные представления из предложенных в документации: GloVe, fastText, ELMo.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/embedders.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "8BDAP9GVcHKI",
    "outputId": "7d02a4f0-a103-41d1-8e74-d4261b1c82d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"in\": [\n",
      "    \"x_tok\"\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"x_emb\"\n",
      "  ],\n",
      "  \"id\": \"my_embedder\",\n",
      "  \"class_name\": \"elmo_embedder\",\n",
      "  \"elmo_output_names\": [\n",
      "    \"elmo\"\n",
      "  ],\n",
      "  \"mini_batch_size\": 32,\n",
      "  \"spec\": \"http://files.deeppavlov.ai/deeppavlov_data/elmo_ru-twitter_2013-01_2018-04_600k_steps.tar.gz\",\n",
      "  \"pad_zero\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(config[\"chainer\"][\"pipe\"][3], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdyZP9obcHKO"
   },
   "source": [
    "## Vocabulary of classes\n",
    "\n",
    "По умолчанию каждый класс считывается и хранится в виде строки.\n",
    "Поэтому мы должны просмотреть все встречающиеся в датасете классы, собрать по ним словарь, а затем преобразовать классы в индексы.\n",
    "\n",
    "Нейросетевые классификаторы принимают one-hot представление распределения по классам, а возвращают распределение вероятностей принадлежности классам.\n",
    "Чтобы получить one-hot представление классов, необходимо также преобразовать полученные из словаря индексы классов.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/core/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wZMh_6VcHKO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"classes_vocab\",\n",
      "  \"class_name\": \"simple_vocab\",\n",
      "  \"fit_on\": [\n",
      "    \"y\"\n",
      "  ],\n",
      "  \"save_path\": \"{MODEL_PATH}/classes.dict\",\n",
      "  \"load_path\": \"{MODEL_PATH}/classes.dict\",\n",
      "  \"in\": \"y\",\n",
      "  \"out\": \"y_ids\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(config[\"chainer\"][\"pipe\"][0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFpd2ciccHKc"
   },
   "source": [
    "**One-hotter**\n",
    "\n",
    "Компонента для преобразования индексов в one-hot представление.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/preprocessors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiXLIj4EcHKc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"in\": \"y_ids\",\n",
      "  \"out\": \"y_onehot\",\n",
      "  \"class_name\": \"one_hotter\",\n",
      "  \"depth\": \"#classes_vocab.len\",\n",
      "  \"single_vector\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(config[\"chainer\"][\"pipe\"][4], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgjLcf5McHKh"
   },
   "source": [
    "**Converting from probability to labels**\n",
    "\n",
    "Так как нейросетевые модели возвращают вероятности распределения по классам, поэтому нам необходимо также преобразовать вектора вероятностей в классы.\n",
    "Для этого используем `Proba2Labels` компоненту для преобразования вероятнсотей в индексы, а далее словарь по классам для преобразования индексов в текстовые назвнаия классов.\n",
    "\n",
    "`Proba2Labels` компонента имеет несколько режимов:\n",
    "* если `max_proba`=true, возвращает индексы с наибольшей вероятностью,\n",
    "* если задано значение `confident_threshold` (от 0 до 1), возвращает индексы, вероятность принадлежности к классам которых выше заданного порога,\n",
    "* если задано целочисленное значение `top_n`, возвращает `top_n` индексов с наибольшими вероятностями.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/preprocessors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwZ_zKZYcHKi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"in\": \"y_pred_probas\",\n",
      "  \"out\": \"y_pred_ids\",\n",
      "  \"class_name\": \"proba2labels\",\n",
      "  \"max_proba\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(config[\"chainer\"][\"pipe\"][6], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnUUkw_AcHKo"
   },
   "source": [
    "## Classifier\n",
    "\n",
    "`DeepPavlov` содержит несколько различных моделей для классификации текстов: классификаторы `sklearn`, нейросетевые модели на `Keras` с `TensorFlow` бэкендом, классификатор на основе BERT  архитектуры на `TensorFlow`.\n",
    "Данный тюториал демонстрирует, как построить нейросетевой классификатор неглубокой широкой свёрточной сети (shallow and wide Convolutional Neural Network) на `Keras`. \n",
    "\n",
    "`KerasClassificationModel` - класс-компонента, строящий `Keras` классификатор, а архитектура сети задается в отдельном методе класса.\n",
    "\n",
    "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/classifiers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XgGTTfgqcHKo",
    "outputId": "97bc4ef2-30dc-4a56-a47a-e73c1137f042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"in\": [\n",
      "    \"x_emb\"\n",
      "  ],\n",
      "  \"in_y\": [\n",
      "    \"y_onehot\"\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"y_pred_probas\"\n",
      "  ],\n",
      "  \"main\": true,\n",
      "  \"class_name\": \"keras_classification_model\",\n",
      "  \"save_path\": \"{MODEL_PATH}/model\",\n",
      "  \"load_path\": \"{MODEL_PATH}/model\",\n",
      "  \"embedding_size\": \"#my_embedder.dim\",\n",
      "  \"n_classes\": \"#classes_vocab.len\",\n",
      "  \"kernel_sizes_cnn\": [\n",
      "    3,\n",
      "    5,\n",
      "    7\n",
      "  ],\n",
      "  \"filters_cnn\": 256,\n",
      "  \"optimizer\": \"Adam\",\n",
      "  \"learning_rate\": 0.01,\n",
      "  \"learning_rate_decay\": 0.1,\n",
      "  \"loss\": \"categorical_crossentropy\",\n",
      "  \"last_layer_activation\": \"softmax\",\n",
      "  \"coef_reg_cnn\": 0.001,\n",
      "  \"coef_reg_den\": 0.01,\n",
      "  \"dropout_rate\": 0.5,\n",
      "  \"dense_size\": 100,\n",
      "  \"model_name\": \"cnn_model\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(config[\"chainer\"][\"pipe\"][5], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметры тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"epochs\": 100,\n",
      "  \"batch_size\": 128,\n",
      "  \"metrics\": [\n",
      "    \"f1_weighted\",\n",
      "    \"f1_macro\",\n",
      "    \"sets_accuracy\",\n",
      "    {\n",
      "      \"name\": \"roc_auc\",\n",
      "      \"inputs\": [\n",
      "        \"y_onehot\",\n",
      "        \"y_pred_probas\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"validation_patience\": 5,\n",
      "  \"val_every_n_epochs\": 1,\n",
      "  \"log_every_n_epochs\": 1,\n",
      "  \"show_examples\": false,\n",
      "  \"evaluation_targets\": [\n",
      "    \"train\",\n",
      "    \"valid\",\n",
      "    \"test\"\n",
      "  ],\n",
      "  \"tensorboard_log_dir\": \"{MODEL_PATH}/logs\",\n",
      "  \"class_name\": \"nn_trainer\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(config[\"train\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"variables\": {\n",
      "    \"ROOT_PATH\": \"~/.deeppavlov\",\n",
      "    \"DOWNLOADS_PATH\": \"{ROOT_PATH}/downloads\",\n",
      "    \"MODELS_PATH\": \"{ROOT_PATH}/models\",\n",
      "    \"MODEL_PATH\": \"{MODELS_PATH}/classifiers/rusentiment_v10\"\n",
      "  },\n",
      "  \"requirements\": [\n",
      "    \"{DEEPPAVLOV_PATH}/requirements/tf.txt\",\n",
      "    \"{DEEPPAVLOV_PATH}/requirements/tf-hub.txt\"\n",
      "  ],\n",
      "  \"labels\": {\n",
      "    \"telegram_utils\": \"IntentModel\",\n",
      "    \"server_utils\": \"KerasIntentModel\"\n",
      "  },\n",
      "  \"download\": [\n",
      "    {\n",
      "      \"url\": \"http://files.deeppavlov.ai/deeppavlov_data/classifiers/rusentiment_v10.tar.gz\",\n",
      "      \"subdir\": \"{MODELS_PATH}/classifiers\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(config[\"metadata\"], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tutorial_1_Sentence_classification_with_word_embeddings.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
