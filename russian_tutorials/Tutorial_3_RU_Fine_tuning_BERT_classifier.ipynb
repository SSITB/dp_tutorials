{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial_3_RU_Fine-tuning BERT classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "display_name": "Deep36_reserve",
      "language": "python",
      "name": "deep36_reserve"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cZRyumBocHJF"
      },
      "source": [
        "# Тюториал 1.  Классификация текстов на основе архитектуры BERT\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/deepmipt/dp_tutorials/blob/master/img/BERT_classification.png?raw=1\" width=\"75%\" />\n",
        "\n",
        "\n",
        "Тюториал имеет следующую структуру:\n",
        "\n",
        "1. [Установка зависимостей и библиотеки](#Установка-зависимостей-и-библиотеки)\n",
        "\n",
        "2. [Скачивание датасета](#Скачивание-датасета)\n",
        "\n",
        "3. [Dataset Reader](#Dataset-Reader): [docs link](https://deeppavlov.readthedocs.io/en/latest/apiref/dataset_readers.html)\n",
        "\n",
        "4. [Dataset Iterator](#Dataset-Iterator): [docs link](https://deeppavlov.readthedocs.io/en/latest/apiref/dataset_iterators.html)\n",
        "\n",
        "5. [BERT Preprocessor](#Preprocessor): [docs link](https://deeppavlov.readthedocs.io/en/latest/components/data_processors.html)\n",
        "\n",
        "6. [Vocabulary of classes](#Vocabulary-of-classes)\n",
        "\n",
        "7. [BERT Classifier](#Classifier): [docs link](https://deeppavlov.readthedocs.io/en/latest/components/classifiers.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0wFSAIVwcHJt"
      },
      "source": [
        "## Установка зависимостей и библиотеки\n",
        "\n",
        "Начнем с установки библиотеки `DeepPavlov` и дополнительных зависимостей для использования нейросетевой модели классификации на основе архитектуры BERT на `TensorFlow`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "82JKwt5_cHJu",
        "colab": {}
      },
      "source": [
        "!pip install deeppavlov"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8foXOlPocHJv",
        "colab": {}
      },
      "source": [
        "!python -m deeppavlov install insults_kaggle_bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quxGE2A2AJ8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m deeppavlov download insults_kaggle_bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rBjOVuFVE1P4"
      },
      "source": [
        "## Скачивание датасета"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pRMjDk79E1Xf"
      },
      "source": [
        "Данный тюториал использует датасет Stanford Sentiment Treebank (SST), описанный в [статье](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf).\n",
        "\n",
        "Датасет содержит набор неразмеченных предложений, разделенных на тренировочную, валидационную и тестовую выборку, а также набор фраз, каждой из которых сопоставлено значение тональности от 0 до 1.\n",
        "Большинство предложений содержатся в наборе фраз. \n",
        "Соответственно, мы выбрали только те предложения, что размечены по тональности, для каждой выборки. \n",
        "Также мы преобразовали значение тональности, разделив интервал от 0 до 1.\n",
        "Для решения многоклассовой задачи классификации разделим интервал на 5 частей: 0.0-0.2 - очень негативные, 0.2-0.4 - негативные, 0.4-0.6 - нейтральные, 0.6-0.8 - позитивные, 0.8-1.0 - очень позитивные.\n",
        "Для сведения к двум классам разделим интервал следующим образом: 0.0-0.4 - негативные, 0.6-1.0 - позитивные."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X2CSOOvQE6wA"
      },
      "source": [
        "Скачаем архив с датасетом и извлечем его."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9evo51p-E6_u",
        "colab": {}
      },
      "source": [
        "from deeppavlov.core.data.utils import download\n",
        "\n",
        "download(\"./stanfordSentimentTreebank.zip\", source_url=\"http://files.deeppavlov.ai/datasets/stanfordSentimentTreebank.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eGe8JOi6FBBS",
        "colab": {}
      },
      "source": [
        "!unzip stanfordSentimentTreebank.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JhY2yQcoFEb0",
        "colab": {}
      },
      "source": [
        "!ls stanfordSentimentTreebank/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-3ecyN0XcHJw"
      },
      "source": [
        "## Dataset Reader\n",
        "\n",
        "DatasetReader - компонента библиотеки для чтения файлов. `DeepPavlov` содержит несколько различных DatasetReaders, пользователи могут как использовать уже готовый DatasetReader, так и написать свою компоненту для чтения данных, однако стоит учитывать, что данные на выходе должны быть в определенном формате. \n",
        "\n",
        "Требования к **DatasetReader**: \n",
        "* на выходе метода `read` должен быть словарь с тремя ключами \"train\", \"valid\" и \"test\", \n",
        "* каждый элемент словаря - лист соответствующих примеров,\n",
        "* каждый пример - tuple `(x, y)`, где `x` и `y` также могут быть листами соответствующих входных данных (например, `x` может быть листом из двух входных текстов, а `y` - листом классов, к которому принадлежит пример).\n",
        "\n",
        "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/dataset_readers.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sSgPZbPAcHJx",
        "colab": {}
      },
      "source": [
        "from deeppavlov.dataset_readers.basic_classification_reader import BasicClassificationDatasetReader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7IMfseBmcHJy",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "reader = BasicClassificationDatasetReader()\n",
        "data = reader.read(data_path=\"./stanfordSentimentTreebank\", \n",
        "                   train=\"train_binary.csv\", valid=\"valid_binary.csv\", test=\"test_binary.csv\",\n",
        "                   x=\"text\", y=\"binary_label\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yHMgaOdfcHJz",
        "colab": {}
      },
      "source": [
        "data.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Si7P1UU6cHJ1"
      },
      "source": [
        "Для задачи классификации по умолчанию каждому примеру ставится в соответствие лист классов. Это сделано для единообразия работы как с многоклассовой классификацией, так и с многолейбловой (когда каждому примеру может соответствовать один или несколько классов)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iMTGWqyJcHJ2",
        "colab": {}
      },
      "source": [
        "data[\"train\"][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z4o1sPsrcHJ3"
      },
      "source": [
        "## Dataset Iterator\n",
        "\n",
        "DatasetIterator - компонента библиотеки для итерирования по датасету (создания батчей, получения всех примеров). `DeepPavlov` содержит несколько разных DatasetIterators, пользователи могут как использовать уже готовый DatasetIterator, так и написать свою компоненту для итерирования по данным\n",
        "\n",
        "DatasetIterator должен иметь следующие методы:\n",
        "\n",
        "* **gen_batches** - метод для генерации батчей входных пар для обучения или инференса нейронной сети. На выходе метода - tuple `(x, y)` из двух листов входных данных `x` и `y`. \n",
        "* **get_instances** - метод для получения данных определенного набора (\"train\", \"valid\", \"test\"). На выходе - tuple `(x, y)` всех элементов входных данных этого набора.\n",
        "* **split** - метод для разделения наборов данных на несколько (\"train\", \"valid\", \"test\").\n",
        "\n",
        "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/dataset_iterators.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G1iWNhFmcHJ4",
        "colab": {}
      },
      "source": [
        "from deeppavlov.dataset_iterators.basic_classification_iterator import BasicClassificationDatasetIterator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7LtY4xKMcHJ5",
        "colab": {}
      },
      "source": [
        "iterator = BasicClassificationDatasetIterator(data, seed=42, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "enx-deI6Fc81",
        "colab": {}
      },
      "source": [
        "for batch in iterator.gen_batches(data_type=\"train\", batch_size=13):\n",
        "    print(batch)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C7q-San0cHJ6"
      },
      "source": [
        "## BERT Preprocessor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wHzWodEgcHJ7",
        "colab": {}
      },
      "source": [
        "from deeppavlov.models.preprocessors.bert_preprocessor import BertPreprocessor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iP0hUsI5cHJ9",
        "colab": {}
      },
      "source": [
        "bert_preprocessor = BertPreprocessor(vocab_file=\"~/.deeppavlov/downloads/bert_models/cased_L-12_H-768_A-12/vocab.txt\",\n",
        "                                     do_lower_case=False,\n",
        "                                     max_seq_length=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bQt4cfRzcHJ_",
        "colab": {}
      },
      "source": [
        "input_features = bert_preprocessor([\"The Rock is destined to be the 21st Century 's new `` Conan ''.\"])\n",
        "input_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qClY-HubCrQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(input_features[0].tokens)\n",
        "print(input_features[0].input_ids)\n",
        "print(input_features[0].input_mask)\n",
        "print(input_features[0].input_type_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fdyZP9obcHKO"
      },
      "source": [
        "## Vocabulary of classes\n",
        "\n",
        "По умолчанию каждый класс считывается и хранится в виде строки.\n",
        "Поэтому мы должны просмотреть все встречающиеся в датасете классы, собрать по ним словарь, а затем преобразовать классы в индексы.\n",
        "\n",
        "Нейросетевые классификаторы принимают one-hot представление распределения по классам, а возвращают распределение вероятностей принадлежности классам.\n",
        "Чтобы получить one-hot представление классов, необходимо также преобразовать полученные из словаря индексы классов.\n",
        "\n",
        "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/core/data.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3wZMh_6VcHKO",
        "colab": {}
      },
      "source": [
        "from deeppavlov.core.data.simple_vocab import SimpleVocabulary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_7O0c273cHKQ",
        "colab": {}
      },
      "source": [
        "vocab = SimpleVocabulary(save_path=\"./binary_classes.dict\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OpRDirSeXLav",
        "colab": {}
      },
      "source": [
        "iterator.get_instances(data_type=\"train\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KO_XRoi0cHKS",
        "colab": {}
      },
      "source": [
        "vocab.fit(iterator.get_instances(data_type=\"train\")[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WqrLgM3wcHKU",
        "colab": {}
      },
      "source": [
        "list(vocab.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "07UYYS-bcHKW",
        "colab": {}
      },
      "source": [
        "vocab([\"positive\", \"positive\", \"negative\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UJgn639-cHKZ",
        "colab": {}
      },
      "source": [
        "vocab([0, 0, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CFpd2ciccHKc"
      },
      "source": [
        "**One-hotter**\n",
        "\n",
        "Компонента для преобразования индексов в one-hot представление.\n",
        "\n",
        "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/preprocessors.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DiXLIj4EcHKc",
        "colab": {}
      },
      "source": [
        "from deeppavlov.models.preprocessors.one_hotter import OneHotter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6EtTb1VgcHKe",
        "colab": {}
      },
      "source": [
        "one_hotter = OneHotter(depth=vocab.len, \n",
        "                       single_vector=True  # means we want to have one vector per sample\n",
        "                      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YTh-O4uvcHKg",
        "colab": {}
      },
      "source": [
        "one_hotter(vocab([\"positive\", \"positive\", \"negative\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RgjLcf5McHKh"
      },
      "source": [
        "**Converting from probability to labels**\n",
        "\n",
        "Так как нейросетевые модели возвращают вероятности распределения по классам, поэтому нам необходимо также преобразовать вектора вероятностей в классы.\n",
        "Для этого используем `Proba2Labels` компоненту для преобразования вероятнсотей в индексы, а далее словарь по классам для преобразования индексов в текстовые назвнаия классов.\n",
        "\n",
        "`Proba2Labels` компонента имеет несколько режимов:\n",
        "* если `max_proba`=true, возвращает индексы с наибольшей вероятностью,\n",
        "* если задано значение `confident_threshold` (от 0 до 1), возвращает индексы, вероятность принадлежности к классам которых выше заданного порога,\n",
        "* если задано целочисленное значение `top_n`, возвращает `top_n` индексов с наибольшими вероятностями.\n",
        "\n",
        "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/preprocessors.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jwZ_zKZYcHKi",
        "colab": {}
      },
      "source": [
        "from deeppavlov.models.classifiers.proba2labels import Proba2Labels\n",
        "\n",
        "prob2labels = Proba2Labels(max_proba=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n4eKuCvqYkqZ",
        "colab": {}
      },
      "source": [
        "vocab.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zVsUXstmcHKk",
        "colab": {}
      },
      "source": [
        "prob2labels([[0.6, 0.4], \n",
        "             [0.2, 0.8],\n",
        "             [0.1, 0.9]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1qCNgjSVGOMP",
        "colab": {}
      },
      "source": [
        "vocab(prob2labels([[0.6, 0.4], \n",
        "                   [0.2, 0.8],\n",
        "                   [0.1, 0.9]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CnUUkw_AcHKo"
      },
      "source": [
        "## BERT Classifier\n",
        "\n",
        "`DeepPavlov` содержит несколько различных моделей для классификации текстов: классификаторы `sklearn`, нейросетевые модели на `Keras` с `TensorFlow` бэкендом, классификатор на основе BERT  архитектуры на `TensorFlow`.\n",
        "Данный тюториал демонстрирует, как построить нейросетевой классификатор на основе архитектуры BERT.\n",
        "\n",
        "**DOCS:** http://docs.deeppavlov.ai/en/latest/apiref/models/classifiers.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XgGTTfgqcHKo",
        "colab": {}
      },
      "source": [
        "from deeppavlov.models.bert.bert_classifier import BertClassifierModel\n",
        "from deeppavlov.metrics.accuracy import sets_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tM6IoNGqcHKp",
        "colab": {}
      },
      "source": [
        "bert_classifier = BertClassifierModel(\n",
        "    n_classes=vocab.len,\n",
        "    return_probas=True,\n",
        "    one_hot_labels=True,\n",
        "    bert_config_file=\"~/.deeppavlov/downloads/bert_models/cased_L-12_H-768_A-12/bert_config.json\",\n",
        "    pretrained_bert=\"~/.deeppavlov/downloads/bert_models/cased_L-12_H-768_A-12/bert_model.ckpt\",\n",
        "    save_path=\"sst_bert_model/model\",\n",
        "    load_path=\"sst_bert_model/model\",\n",
        "    keep_prob=0.5,\n",
        "    learning_rate=1e-05,\n",
        "    learning_rate_drop_patience=5,\n",
        "    learning_rate_drop_div=2.0\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ITs_wpucHKq",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# Method `get_instances` returns all the samples of particular data field\n",
        "x_valid, y_valid = iterator.get_instances(data_type=\"valid\")\n",
        "# You need to save model only when validation score is higher than previous one.\n",
        "# This variable will contain the highest accuracy score\n",
        "best_score = 0.\n",
        "patience = 2\n",
        "impatience = 0\n",
        "\n",
        "# let's train for 3 epochs\n",
        "for ep in range(3):\n",
        "  \n",
        "    nbatches = 0\n",
        "    for x, y in iterator.gen_batches(batch_size=64, \n",
        "                                     data_type=\"train\", shuffle=True):\n",
        "        x_feat = bert_preprocessor(x)\n",
        "        y_onehot = one_hotter(vocab(y))\n",
        "        bert_classifier.train_on_batch(x_feat, y_onehot)\n",
        "        print(\"Batch done\\n\")\n",
        "        nbatches += 1\n",
        "        \n",
        "        if nbatches % 1 == 0:\n",
        "            # валидируемся каждые 100 батчей\n",
        "            y_valid_pred = bert_classifier(bert_preprocessor(x_valid))\n",
        "            score = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))\n",
        "            print(\"Batches done: {}. Valid Accuracy: {}\".format(nbatches, score))\n",
        "            \n",
        "    y_valid_pred = bert_classifier(bert_preprocessor(x_valid))\n",
        "    score = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))\n",
        "    print(\"Epochs done: {}. Valid Accuracy: {}\".format(ep + 1, score))\n",
        "    if score > best_score:\n",
        "        bert_classifier.save()\n",
        "        print(\"New best score. Saving model.\")\n",
        "        best_score = score    \n",
        "        impatience = 0\n",
        "    else:\n",
        "        impatience += 1\n",
        "        if impatience == patience:\n",
        "            print(\"Out of patience. Stop training.\")\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6mXMUtrpcHKt",
        "colab": {}
      },
      "source": [
        "# Let's look into obtained resulting outputs\n",
        "print(\"Text sample: {}\".format(x_valid[0]))\n",
        "print(\"True label: {}\".format(y_valid[0]))\n",
        "print(\"Predicted probability distribution: {}\".format(dict(zip(vocab.keys(), \n",
        "                                                               y_valid_pred[0]))))\n",
        "print(\"Predicted label: {}\".format(vocab(prob2labels(y_valid_pred))[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOPUHo2qBTqg",
        "colab_type": "text"
      },
      "source": [
        "# Подключение к Telegram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDT_4eicBVxQ",
        "colab_type": "text"
      },
      "source": [
        "`DeepPavlov` поддерживает подключение моделей и ботов к следующим сервисам:\n",
        "\n",
        "* [REST API](http://docs.deeppavlov.ai/en/master/intro/features.html#examples-of-some-components)\n",
        "* [Telegram](http://docs.deeppavlov.ai/en/master/intro/features.html#examples-of-some-components)\n",
        "* [Amazon Alexa](http://docs.deeppavlov.ai/en/master/devguides/amazon_alexa.html)\n",
        "* [Microsoft Bot Framework](http://docs.deeppavlov.ai/en/master/devguides/ms_bot_integration.html)\n",
        "  * Bing, Cortana, Email, Facebook Messenger, Slack, GroupMe, Microsoft Teams, Skype, Telegram, Twilio, Web Chat\n",
        "* [Yandex Alice](http://docs.deeppavlov.ai/en/master/devguides/yandex_alice.html)\n",
        "\n",
        "В данном тюториале рассмотрим, как подключить полученную модель к Telegram."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88pdPGzu99Mh",
        "colab_type": "text"
      },
      "source": [
        "## Подключение из командной строки\n",
        "\n",
        "`DeepPavlov` использует следующие команды:\n",
        "\n",
        "Запустить модель в интерфейсе командной строки:\n",
        "```\n",
        "python -m deeppavlov interact model_config\n",
        "```\n",
        "\n",
        "Поднять REST API:\n",
        "```\n",
        "python -m deeppavlov riseapi model_config\n",
        "```\n",
        "\n",
        "Подключить к Telegram:\n",
        "```\n",
        "python -m deeppavlov interactbot model_config -t <TELEGRAM_TOKEN>\n",
        "```\n",
        "\n",
        "Telegram token может быть создан с помощью  @BotFather. Подробнее прочитайте [здесь](https://core.telegram.org/bots#3-how-do-i-create-a-bot)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytRBeu8M99Ml",
        "colab_type": "text"
      },
      "source": [
        "## Подключение без конфига\n",
        "\n",
        "В данном тюториале мы не создавали конфиг для модели, поэтому давайте попробуем поднять сервис, также не используя конфиг."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USakwUMY99Mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentPipeline:\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, input_texts):\n",
        "        '''\n",
        "        __call__ method should return responses for each utterance in input_texts\n",
        "        '''\n",
        "        \n",
        "        sentiment_labels = vocab(prob2labels(model(embedder(tokenizer(preprocessor(input_texts))))))\n",
        "        sentiment_labels = [lab[0] for lab in sentiment_labels]\n",
        "        \n",
        "        return sentiment_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSIukUEN99Mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_config(class_name):\n",
        "    \"\"\"generate minimal required DeepPavlov model configuration\"\"\"\n",
        "\n",
        "    config = {\n",
        "        'chainer': {\n",
        "            'in': ['x'],\n",
        "            'out': ['y'],\n",
        "            'pipe': [\n",
        "                {\n",
        "                    'class_name': f'__main__:{class_name}',\n",
        "                    'in': ['x'],\n",
        "                    'out': ['y']\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    return config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qayRJBxI99Mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to interact with CLI\n",
        "from deeppavlov.core.commands.infer import interact_model\n",
        "# to interact with Telegram\n",
        "from deeppavlov.utils.telegram.telegram_ui import interact_model_by_telegram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4n3sOnr99Mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interact_model(generate_config('SentimentPipeline'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLeXU30V99Mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interact_model_by_telegram(generate_config('SentimentPipeline'), \n",
        "                           token='YOUR_TOKEN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF_h9bvq99Mz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lu5LXp399M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}